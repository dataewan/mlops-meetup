{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808a2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from mlops_meetup import parquet_ingest, config, datawarehouse, modelling\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc27cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2187c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-07-11 17:59:22+0100] INFO - prefect.FlowRunner | Beginning Flow run for 'Training run'\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'create_lookups': Starting task run...\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'create_lookups': Finished task run for task with final state: 'Success'\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'get_max_ids': Starting task run...\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'get_max_ids': Finished task run for task with final state: 'Success'\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'get_max_ids[1]': Starting task run...\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'get_max_ids[1]': Finished task run for task with final state: 'Success'\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'get_max_ids[0]': Starting task run...\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'get_max_ids[0]': Finished task run for task with final state: 'Success'\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'training_data': Starting task run...\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.TaskRunner | Task 'training_data': Finished task run for task with final state: 'Success'\n",
      "[2021-07-11 17:59:22+0100] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "with prefect.Flow(\"Training run\") as f:\n",
    "    con = datawarehouse.connect_dw()\n",
    "    lookups = datawarehouse.create_lookups(\n",
    "        con\n",
    "    )\n",
    "\n",
    "    max_item_id, max_user_id = datawarehouse.get_max_ids(con)\n",
    "    training_data = datawarehouse.training_data(con, upstream_tasks=[lookups])\n",
    "\n",
    "state = f.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fead2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = state.result[training_data]._result.value\n",
    "max_item_id_value = state.result[max_item_id]._result.value\n",
    "max_user_id_value = state.result[max_user_id]._result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be21d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=32\n",
    "\n",
    "user_input = layers.Input(shape=(1,), name=\"user\")\n",
    "item_input = layers.Input(shape=(1,), name=\"item\")\n",
    "\n",
    "user_embedding = layers.Embedding(\n",
    "    name=\"user_embedding\", input_dim=max_user_id_value + 1, output_dim=embedding_size\n",
    ")(user_input)\n",
    "item_embedding = layers.Embedding(\n",
    "    name=\"item_embedding\", input_dim=max_item_id_value + 1, output_dim=embedding_size\n",
    ")(item_input)\n",
    "\n",
    "dot = layers.Dot(\n",
    "    name=\"dot_product\",\n",
    "    normalize=True,\n",
    "    axes=2,\n",
    ")([item_embedding, user_embedding])\n",
    "\n",
    "merged = layers.Reshape((1,))(dot)\n",
    "\n",
    "model = keras.Model(inputs=[user_input, item_input], outputs=[merged])\n",
    "\n",
    "model.compile(optimizer=\"nadam\", loss=\"mse\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be563ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empty_batch(n_positive_examples, negative_ratio):\n",
    "    batch_size = (1 + negative_ratio) * n_positive_examples\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    return batch\n",
    "\n",
    "\n",
    "def negative_sampler(data, positive_indexes, negative_ratio):\n",
    "    mask = np.ones(len(data[\"user_id\"]), np.bool)\n",
    "    mask[positive_indexes] = 0\n",
    "    users = data[\"user_id\"][positive_indexes]\n",
    "    negative_users = np.tile(users, negative_ratio)\n",
    "    \n",
    "    items = data[\"item_id\"][mask]\n",
    "    negative_items = np.random.choice(items, len(negative_users))\n",
    "    \n",
    "    return negative_users, negative_items\n",
    "\n",
    "def batchifier(data, n_positive_examples, negative_ratio):\n",
    "    batch = make_empty_batch(n_positive_examples, negative_ratio)\n",
    "    ids = np.arange(len(data[\"user_id\"]))\n",
    "    while True:\n",
    "        positive_indexes = np.random.choice(ids, n_positive_examples)\n",
    "        batch[:n_positive_examples, 0] = data[\"user_id\"][positive_indexes]\n",
    "        batch[:n_positive_examples, 1] = data[\"item_id\"][positive_indexes]\n",
    "        # give them a score of 1\n",
    "        batch[:n_positive_examples, 2] = 1\n",
    "        \n",
    "        negative_users, negative_items = negative_sampler(\n",
    "            data,\n",
    "            positive_indexes,\n",
    "            negative_ratio\n",
    "        )\n",
    "        \n",
    "        # give them the score of -1\n",
    "\n",
    "        batch[n_positive_examples:, 0] = negative_users\n",
    "        batch[n_positive_examples:, 1] = negative_items\n",
    "        batch[n_positive_examples:, 2] = -1\n",
    "        \n",
    "        np.random.shuffle(batch)\n",
    "        \n",
    "        yield {\n",
    "            \"user\": batch[:, 0],\n",
    "            \"item\": batch[:, 1],\n",
    "        }, batch[:, 2]\n",
    "\n",
    "a = batchifier(data, \n",
    "           n_positive_examples=256, \n",
    "           negative_ratio=10, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5af5cb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "56/56 - 1s - loss: 1.0256\n",
      "Epoch 2/25\n",
      "56/56 - 1s - loss: 1.0174\n",
      "Epoch 3/25\n",
      "56/56 - 1s - loss: 1.0009\n",
      "Epoch 4/25\n",
      "56/56 - 1s - loss: 0.9721\n",
      "Epoch 5/25\n",
      "56/56 - 1s - loss: 0.9118\n",
      "Epoch 6/25\n",
      "56/56 - 1s - loss: 0.8109\n",
      "Epoch 7/25\n",
      "56/56 - 1s - loss: 0.6918\n",
      "Epoch 8/25\n",
      "56/56 - 1s - loss: 0.5760\n",
      "Epoch 9/25\n",
      "56/56 - 1s - loss: 0.4908\n",
      "Epoch 10/25\n",
      "56/56 - 1s - loss: 0.4238\n",
      "Epoch 11/25\n",
      "56/56 - 1s - loss: 0.3789\n",
      "Epoch 12/25\n",
      "56/56 - 1s - loss: 0.3498\n",
      "Epoch 13/25\n",
      "56/56 - 1s - loss: 0.3306\n",
      "Epoch 14/25\n",
      "56/56 - 1s - loss: 0.3157\n",
      "Epoch 15/25\n",
      "56/56 - 1s - loss: 0.3069\n",
      "Epoch 16/25\n",
      "56/56 - 1s - loss: 0.2999\n",
      "Epoch 17/25\n",
      "56/56 - 1s - loss: 0.2950\n",
      "Epoch 18/25\n",
      "56/56 - 1s - loss: 0.2910\n",
      "Epoch 19/25\n",
      "56/56 - 1s - loss: 0.2876\n",
      "Epoch 20/25\n",
      "56/56 - 1s - loss: 0.2851\n",
      "Epoch 21/25\n",
      "56/56 - 1s - loss: 0.2829\n",
      "Epoch 22/25\n",
      "56/56 - 1s - loss: 0.2810\n",
      "Epoch 23/25\n",
      "56/56 - 1s - loss: 0.2794\n",
      "Epoch 24/25\n",
      "56/56 - 1s - loss: 0.2778\n",
      "Epoch 25/25\n",
      "56/56 - 1s - loss: 0.2769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16f8a43a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    a,\n",
    "    epochs=25,\n",
    "    steps_per_epoch=len(data[\"user_id\"]) // 256,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62b18b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'user_embedding/embeddings:0' shape=(10980, 32) dtype=float32, numpy=\n",
       "array([[-7.4076168e-03,  2.6773661e-05, -4.0767230e-02, ...,\n",
       "         3.7153687e-02, -3.1127274e-02,  1.9083370e-02],\n",
       "       [ 4.9473112e-03, -3.2740187e-02,  8.2770037e-03, ...,\n",
       "        -8.9771915e-03, -4.5250885e-02, -4.5312863e-02],\n",
       "       [-1.5054723e-02, -2.1298775e-02,  1.4644582e-02, ...,\n",
       "         3.5936128e-02, -4.0803108e-02, -1.8823575e-02],\n",
       "       ...,\n",
       "       [-2.3449248e-02, -9.3753878e-03,  1.9535035e-02, ...,\n",
       "         1.4218117e-02, -5.9859985e-03, -3.1603411e-02],\n",
       "       [-6.4728200e-02, -7.0344158e-02,  3.4125306e-02, ...,\n",
       "         2.4803118e-03, -2.2856964e-02, -5.3252839e-02],\n",
       "       [-5.0490484e-02, -4.1035701e-02,  3.8105752e-02, ...,\n",
       "         9.2800949e-03, -2.2715569e-02,  1.1011964e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30daf12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10978"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41af4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
